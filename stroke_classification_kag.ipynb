{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Stroke Binary Classification\n## by Dahlia Weinberg","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statistics as stat\n\nfrom pprint import pprint\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import recall_score\n\nplt.style.use('seaborn-darkgrid')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploritory Data Analysis","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"round(df.describe()).T","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.nunique()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(dpi=120)\nsns.heatmap(df.corr(), annot=True)\nplt.title('correlation matrix', weight='bold')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stroke has some correlation with age. \n### Age and BMI have some correlation.","metadata":{}},{"cell_type":"code","source":"df.stroke.value_counts(normalize=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The target is only 5% of the dataset.  \n### This means the dataset is unbalanced.","metadata":{}},{"cell_type":"code","source":"sns.boxplot(x='stroke', y='age', data=df, palette='rainbow')\nplt.ylim(-10,100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The median age for people with stroke significantly higher.","metadata":{}},{"cell_type":"code","source":"df.gender.value_counts(normalize=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(x='gender', y='age', data=df, palette='rainbow')\nplt.ylim(-10,100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### There are more males than females in this dataset but it's not overwhelmingly skewed. \n### The age distribution is pretty similar.","metadata":{}},{"cell_type":"code","source":"df.hypertension.value_counts(normalize=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(x='hypertension', y='age', data=df, palette='rainbow')\nplt.ylim(-10,100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.heart_disease.value_counts(normalize=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(x='heart_disease', y='age', data=df, palette='rainbow')\nplt.ylim(-10,100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.smoking_status.value_counts(normalize=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(x='smoking_status', y='age', data=df, palette='rainbow')\nplt.ylim(-10,100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.ever_married.value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(x='ever_married', y='age', data=df, palette='rainbow')\nplt.ylim(-10,100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.Residence_type.value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(x='Residence_type', y='age', data=df, palette='rainbow')\nplt.ylim(-10,100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.work_type.value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(x='work_type', y='age', data=df, palette='rainbow')\nplt.ylim(-10,100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Histrograms for numerical features","metadata":{}},{"cell_type":"code","source":"df.hist('age', bins=30)\nplt.title(\"Age Distribution\", weight='bold')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.hist('avg_glucose_level', bins=30)\nplt.xlabel(\"Average Glucose Level\")\nplt.ylabel(\"Count\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.hist('bmi', bins=30)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(dpi=120)\ndf.groupby('stroke')['age'].plot(kind='hist', bins=30, legend=True,\n                                             alpha=0.7, title='Stroke by Age' )\nplt.xlabel('Age')\nplt.legend(shadow=True, frameon=True)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(dpi=120)\ndf_stroke = df[df.stroke==1]\nplt.hist(df_stroke.age, bins=70)\nplt.title('Age distribution of people with stroke')\nplt.axvline(40, color='red', linestyle='dashed', linewidth=2)\nplt.xlabel('Age')\nplt.ylabel('Count')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stroke rises with age and is barely present under the age of 40.","metadata":{}},{"cell_type":"markdown","source":"# Data Cleaning","metadata":{}},{"cell_type":"markdown","source":"### 1. Gender Feature","metadata":{}},{"cell_type":"code","source":"df.gender.value_counts()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(df[df['gender']=='Other'].index,inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df['gender']=='Other'].index","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['gender'].replace({'Male':1, 'Female':2},  inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Stroke and Age - cleaning outliers","metadata":{}},{"cell_type":"code","source":"sns.boxplot(x='stroke', y='age', data=df, palette='rainbow')\nplt.ylim(-10,100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.query('age < 20 and stroke==1')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(index=[162, 245], axis=0, inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(x='stroke', y='age', data=df, palette='rainbow')\nplt.ylim(-10,100)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Data imputation of missing values in BMI feature.\nThe Nan (missing values) were replaced with average BMI from their respective BMI age bins. ","metadata":{}},{"cell_type":"code","source":"plt.figure(dpi=120)\nsns.heatmap(df.isnull(), yticklabels=False, cbar=False)\nplt.title(\"Missing Values Heat Map\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.age.max()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create age bins\nbins = [0, 40, 45, 50, 55, 60, 65, 70, 75, 82]\ndf['age_group']=pd.cut(df.age, bins)\ndf[['id', 'age', 'age_group']].sample(5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate average BMI for each age bin\nage_group_to_meanbmi = df.groupby('age_group').mean()['bmi']\nage_group_to_meanbmi","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# replace missing values with age group mean BMI values\nage_group_to_meanbmi = df.groupby('age_group').mean()['bmi']\nfor index, column in df.iterrows():\n    if np.isnan(column.bmi):\n        mean_bmi = column.age_group\n        df.loc[index, 'bmi'] = age_group_to_meanbmi[mean_bmi]\n\nplt.figure(dpi=120)\nsns.heatmap(df.isnull(), yticklabels=False, cbar=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4. DF over 40 - making dataset more balanced.","metadata":{}},{"cell_type":"code","source":"df_over_40 = df[df.age >= 40]\ndf_over_40.sample()\n#df_over_40.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# now the target is 8% rather than less than 5%\ndf_over_40.stroke.value_counts(normalize=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5. Turning smoking to a numerical feature using dummy","metadata":{}},{"cell_type":"code","source":"dummy_smoker = pd.get_dummies(df.smoking_status, drop_first=False, prefix='Smoker')\ndummy_smoker.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dummy_smoker.shape, df.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([df, dummy_smoker], axis=1)\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Function for data cleaning","metadata":{}},{"cell_type":"code","source":"def clean_data(df: pd.DataFrame):\n    \n    #remove unknown gender (single row)\n    df.drop(df[df['gender']=='Other'].index,inplace=True)\n    \n    #turning the gender feature from a string to numerical\n    df['gender'].replace({'Male':1, 'Female':2},  inplace=True)\n    \n    # removing age outliers for stroke\n    df.drop(index=[162, 245], axis=0, inplace=True)\n    \n    #placing bmi average/age to missing bmi values\n    bins = [0, 40, 45, 50, 55, 60, 65, 70, 75, 82]\n    pd.cut(df.age, bins)\n    df['age_group']=pd.cut(df.age, bins)\n    age_group_to_meanbmi = df.groupby('age_group').mean()['bmi']\n    for index, column in df.iterrows():\n        if np.isnan(column.bmi):\n            mean_bmi = column.age_group\n            df.loc[index, 'bmi'] = age_group_to_meanbmi[mean_bmi]\n            \n    #limiting the age to 40 and up.\n    df = df[df.age >= 40]\n    \n    #making smoking statues a numerical feature\n    dummy_smoker = pd.get_dummies(df.smoking_status, drop_first=False, prefix='Smoker')\n    df = pd.concat([df, dummy_smoker], axis=1)\n    \n    return df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data cleaning function","metadata":{}},{"cell_type":"code","source":"df_raw = pd.read_csv(\"/kaggle/input/stroke-prediction-dataset/healthcare-dataset-stroke-data.csv\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_final = clean_data(df_raw)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_final.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_final.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Analysis","metadata":{}},{"cell_type":"code","source":"df_final.columns","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The feature with the most visible correlation with stroke is age, glucose levels and BMI. ","metadata":{}},{"cell_type":"code","source":"sns.pairplot(df_final[['age', 'avg_glucose_level', 'bmi', 'stroke',]], hue='stroke')\nplt.show()","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# showing the distribution of stroke in the 40+ population\ndf_final.groupby('stroke')['age'].plot(kind='hist', bins=30, legend=True,\n                                             alpha=0.7, title='Stroke by Age' )\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training the stroke model","metadata":{}},{"cell_type":"markdown","source":"## Features found to be of significance in the Data Analysis\n","metadata":{}},{"cell_type":"code","source":"X_features = ['gender','age', 'hypertension', 'heart_disease','avg_glucose_level', 'bmi', 'Smoker_Unknown', \n              'Smoker_formerly smoked', 'Smoker_never smoked', 'Smoker_smokes']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Baseline Models - Decision Tree was found to be the model with the highest performance","metadata":{}},{"cell_type":"code","source":"dtree = DecisionTreeClassifier()\n\nmodel = dtree\n\n\nX = df_final[X_features]\ny = df_final.stroke\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=101)\nmodel.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Baseline Train","metadata":{}},{"cell_type":"code","source":"y_pred = model.predict(X_train)\nconfusion_matrix(y_train, y_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_train, y_pred))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Baseline test","metadata":{}},{"cell_type":"code","source":"y_pred_test = model.predict(X_test)\nprint(confusion_matrix(y_test, y_pred_test))\nprint(classification_report(y_test, y_pred_test))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Decision tree train was overfit and test was low. Yet it was the most effective of the classifiers.  ","metadata":{}},{"cell_type":"markdown","source":"## Finding the features of greatest importance.","metadata":{}},{"cell_type":"markdown","source":"# Hyperparameter Tuning","metadata":{}},{"cell_type":"markdown","source":"# Decision Tree Random Grid Search","metadata":{}},{"cell_type":"code","source":"dtree = DecisionTreeClassifier()\n\n# Look at parameters used by our current dtree\nprint('Parameters currently in use:\\n')\npprint(dtree.get_params())","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_grid = {'splitter' : [\"best\", \"random\"],\n              'max_depth':[10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], \n              'min_samples_split' : [1, 2, 3, 4],\n              'min_samples_leaf': [2, 5, 8, 10]}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid = GridSearchCV(DecisionTreeClassifier(), param_grid, scoring='recall', refit=True,verbose=1)\ngrid.fit(X_train,y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid.best_score_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid.best_params_","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cost complexity pruning - Hyperparameter tuning ","metadata":{}},{"cell_type":"code","source":"alphas = [0.001, 0.0013, 0.0017, 0.002, 0.0023, 0.0027, 0.003, 0.0033, 0.0037, \n         0.004, 0.0043, 0.0047, 0.005, 0.0053, 0.0057, 0.006, 0.01]\n\ntrain_recall_scores = []\ntest_recall_scores = []\n\nfor alpha in alphas:\n    dtree = DecisionTreeClassifier(\n        ccp_alpha = alpha, class_weight='balanced', criterion='gini', random_state=42, \n        max_depth=100, min_samples_split=8, min_samples_leaf=2, splitter='best')\n    \n    dtree.fit(X_train, y_train)\n    y_pred = dtree.predict(X_train)\n    train_recall_score = recall_score(y_train, y_pred)\n    train_recall_scores.append(train_recall_score)\n    \n    y_pred_test = dtree.predict(X_test)\n    test_recall_score = recall_score(y_test, y_pred_test)\n    test_recall_scores.append(test_recall_score)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(dpi=120)\n\nplt.plot(alphas, train_recall_scores, marker='o', label=\"train\",\n        drawstyle=\"steps-post\")\nplt.plot(alphas, test_recall_scores, marker='o', label=\"test\",\n        drawstyle=\"steps-post\")\nplt.xlabel(\"alpha\")\nplt.ylabel(\"recall\")\nplt.title(\"recall vs alpha for training and testing sets\")\nplt.legend(loc='center right', shadow=True, frameon=True)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## *** The graph showes that the ideal ccp_alpha for both train and test was 0.0053 ","metadata":{}},{"cell_type":"code","source":"# The hyperparameter class_weight was tested with 'weights' and 'balanced'. The 'balanced' was more effective.\n# weights = {0:10, 1:90}\n# for criterion entropy caused overfitting\ndtree = DecisionTreeClassifier(\n    ccp_alpha = 0.0053, \n    class_weight='balanced', \n    criterion='gini', \n    random_state=42, \n    max_depth=20, \n    min_samples_split=2, \n    min_samples_leaf=3,\n    splitter='best')\n\nmodel = dtree","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df_final[X_features]\ny = df_final.stroke\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=101)\nmodel.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training the Decision Tree","metadata":{}},{"cell_type":"code","source":"y_pred = model.predict(X_train)\nconfusion_matrix(y_train, y_pred)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_train, y_pred))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test Decision Tree Model","metadata":{}},{"cell_type":"code","source":"y_pred_test = model.predict(X_test)\nprint(confusion_matrix(y_test, y_pred_test))\nprint(classification_report(y_test, y_pred_test))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_names = list(X_train.columns)\n\nimportances = list(model.feature_importances_)\n\ndata_dict = {'feature_names': feature_names,\n            'importances': importances}\n\ndata_dict\n\n\ndf_features = pd.DataFrame(data_dict)\ndf_features.sort_values(by='importances', ascending=False, inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_features","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(dpi=100)\nplt.bar(x=df_features.feature_names, height=df_features.importances)\nplt.xticks(rotation=90)\nplt.title('Feature Importance')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusions:\n### Decision tree was the model with the best performance. \nThe most important features in this model were age, BMI and average glucose level. <br>\nThe train set was overfit.<br>\nHyperparameters were tuned to overcome this problem.<br>\nGrid search found that 'entropy' was better than 'gini' but this was also causing overfitting in the train.<br> \nThe best tuning was found using:\n1. class_weight as 'balanced'\n2. finding the best ccp_alpha by optimizing for recall\n\nThe recall was thoroughly improved. <br>This was the most important aspect of the classification, since the idea was to identify those at risk of stroke.<br>\nThe precision and the f1 score were low.\n","metadata":{}}]}